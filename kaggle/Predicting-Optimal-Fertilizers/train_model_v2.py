import os
from collections import Counter

import joblib
import numpy as np
import pandas as pd
import torch
from lightgbm import LGBMClassifier
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, TargetEncoder
from sklearn.preprocessing import StandardScaler
from torch import nn, optim
from torch.utils.data import TensorDataset, DataLoader
from xgboost import XGBClassifier
import joblib
from data_preprocessing import save_processed_data

le = LabelEncoder()

def add_agricultural_features(df):
    '''
    æ„é€ å†œä¸šé¢†åŸŸç‰¹å¾
    :param df:
    :return:
    '''
    # NPK æ€»å’Œ
    df['NPK_Sum'] = df['Nitrogen'] + df['Phosphorous'] + df['Potassium']

    # N/P æ¯”ä¾‹
    df['N_P_Ratio'] = df['Nitrogen'] / (df['Phosphorous'] + 1e-5)

    # P/K æ¯”ä¾‹
    df['P_K_Ratio'] = df['Phosphorous'] / (df['Potassium'] + 1e-5)

    # ç¯å¢ƒé€‚å®œæ€§æŒ‡æ ‡ï¼ˆæ¸©åº¦ Ã— æ¹¿åº¦ Ã— æ°´åˆ†ï¼‰
    df['Env_Index'] = df['Temparature'] * df['Humidity'] * df['Moisture']

    # è‚¥åŠ›ç»¼åˆè¯„åˆ†ï¼ˆå‡è®¾ N=0.3, P=0.3, K=0.4 æƒé‡ï¼‰
    df['Fertility_Score'] = (
            df['Nitrogen'] * 0.3 +
            df['Phosphorous'] * 0.3 +
            df['Potassium'] * 0.4
    )

    # å¢åŠ ä½œç‰©å¯¹è¥å…»å…ƒç´ çš„åå¥½ç‰¹å¾ï¼ˆç¤ºä¾‹ï¼‰
    crop_n_preference = {
        'Wheat': 0.8,
        'Maize': 0.7,
        'Oil seeds': 0.3,
        'Paddy': 0.5,
        'Cotton': 0.6,
        'Barley': 0.7,
        'Millets': 0.5,
        'Sugarcane': 0.4,
        'Ground Nuts': 0.4,
        'Tobacco': 0.5,
        'Pulses': 0.4
    }

    df['Crop_Nitrogen_Preference'] = df['Crop Type'].map(crop_n_preference).fillna(0.5)
    df['Weighted_N'] = df['Nitrogen'] * df['Crop_Nitrogen_Preference']
    df['N_sqrt'] = np.sqrt(df['Nitrogen'])
    df['NK_ratio'] = df['Nitrogen'] / (df['Potassium'] + 1e-5)
    return df


def load_data_and_preprocess(data='train.csv'):
    '''
    åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†
    :return:
    '''
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(current_dir, 'data')

    print("å¼€å§‹åŠ è½½æ•°æ®å¹¶å¤„ç†")

    # -----------------------------
    # 1. åŠ è½½æ•°æ®
    # -----------------------------
    file_path = os.path.join(data_dir, data)
    df = pd.read_csv(file_path)

    # -----------------------------
    # 3. æ„é€ å†œä¸šé¢†åŸŸç‰¹å¾
    # -----------------------------
    # åº”ç”¨ç‰¹å¾æ„é€ 
    df = add_agricultural_features(df)

    # -----------------------------
    # 4. ç‰¹å¾ç¼–ç å¤„ç†
    # -----------------------------
    # ç‰¹å¾å’Œæ ‡ç­¾
    X = df.drop(columns=['Fertilizer Name', 'id'])
    y = df['Fertilizer Name'].values

    # âœ… æ·»åŠ è¿™ä¸€æ®µæ¥å¯¹ y è¿›è¡Œç¼–ç 
    y = le.fit_transform(y)
    print("âœ… ç›®æ ‡å˜é‡å·²ç¼–ç ä¸ºæ•°å€¼ç±»å‹:", dict(enumerate(le.classes_)))

    # ä¿å­˜ LabelEncoder
    joblib.dump(le, os.path.join(current_dir, 'label_encoder.pkl'))
    print("âœ… LabelEncoder å·²ä¿å­˜")

    # ç±»åˆ«å‹åˆ—å’Œæ•°å€¼å‹åˆ—
    categorical_cols = ['Soil Type', 'Crop Type']
    numerical_cols = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']
    # æ‰€æœ‰ç‰¹å¾åˆ—ä¸­ç­›é€‰å‡ºâ€œæ—¢ä¸æ˜¯ç±»åˆ«å‹ä¹Ÿä¸æ˜¯æ•°å€¼å‹â€çš„åˆ—ï¼Œ å³æ„é€ çš„å†œä¸šé¢†åŸŸæ–°ç‰¹å¾ï¼ˆå¦‚ NPK æ¯”ä¾‹ã€ç¯å¢ƒå› å­ç­‰ï¼‰

    agri_feature_cols = [col for col in X.columns if col not in categorical_cols + numerical_cols]

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', TargetEncoder(), categorical_cols),
            ('num', StandardScaler(), numerical_cols + agri_feature_cols)
        ],
        remainder='passthrough'
    )
    X_processed = preprocessor.fit_transform(X, y)

    # âœ… ä¿å­˜å·²ç» fit å¥½çš„ preprocessor
    joblib.dump(preprocessor, os.path.join(current_dir, 'scaler.pkl'))
    print("âœ… ColumnTransformer å·²ä¿å­˜ä¸º scaler.pkl")

    # å°†ç¼–ç åçš„ y æ·»åŠ ä¸ºæ–°åˆ—
    feature_names = preprocessor.get_feature_names_out()
    # è½¬æ¢ä¸º pandas DataFrame
    X_processed_df = pd.DataFrame(X_processed, columns=feature_names)

    # å¦‚æœä½ è¿˜æƒ³æ·»åŠ åŸå§‹çš„ Fertilizer Nameï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰ä¹Ÿå¯ä»¥åŠ ä¸Š
    df_original = pd.read_csv(os.path.join(data_dir, 'train.csv'))
    original_labels = df_original['Fertilizer Name'].values
    X_processed_df['Fertilizer Name'] = original_labels  # åŸå§‹å­—ç¬¦ä¸²æ ‡ç­¾ï¼ˆä¾¿äºäººå·¥ç†è§£ï¼‰

    # âœ… æŠŠå½“å‰å¤„ç†åçš„Xå’Œyå­˜å…¥ä¸€ä¸ªæ–°çš„csvä¸­
    save_processed_data(X_processed_df, 'processed_train.csv')
    print("âœ… å·²ä¿å­˜å¤„ç†åçš„æ•°æ®è‡³ processed_train.csv")

    # åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†
    X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)
    print("âœ… æ•°æ®å¤„ç†å®Œæ¯•")
    return X_train, X_val, y_train, y_val



def main():
    print("ğŸš€ å¯åŠ¨ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒæµç¨‹")
    X_train, X_val, y_train, y_val = load_data_and_preprocess()

    # -----------------------------
    # 5.1 æ¨¡å‹è®­ç»ƒï¼šXGBoost
    # -----------------------------
    print("\nğŸŒ³ æ­£åœ¨è®­ç»ƒ XGBoost æ¨¡å‹...")

    model = XGBClassifier(
        n_estimators=3000,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.7,
        colsample_bytree=0.7,
        eval_metric='mlogloss',
        early_stopping_rounds=20,
        use_label_encoder=False,
        verbosity=0,
        random_state=42
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        verbose=100
    )
    print("\nğŸŒ³ è®­ç»ƒ XGBoost æ¨¡å‹å®Œæ¯•")
    # ä¿å­˜æ¨¡å‹
    model.save_model('xgboost_model.json')

    # -----------------------------
    # å•ä¸€ç»“æœæ¨¡å‹è¯„ä¼°
    # -----------------------------
    print("\nğŸ“‹ å•ä¸€ç»“æœæ¨¡å‹è¯„ä¼°ä¸­...")
    y_pred = model.predict(X_val)
    acc = accuracy_score(y_val, y_pred)

    print(f"\nâœ… éªŒè¯é›†å‡†ç¡®ç‡: {acc:.4f}")
    print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_val, y_pred))


def val():
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•

    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(current_dir, 'data')
    print("")

    # -----------------------------
    # 1. åŠ è½½æ•°æ®
    # -----------------------------
    file_path = os.path.join(data_dir, 'train.csv')
    df = pd.read_csv(file_path)
    # -----------------------------
    # 3. æ„é€ å†œä¸šé¢†åŸŸç‰¹å¾
    # -----------------------------
    # åº”ç”¨ç‰¹å¾æ„é€ 
    df = add_agricultural_features(df)

    # -----------------------------
    # 4. ç‰¹å¾ç¼–ç å¤„ç†
    # -----------------------------
    # ç‰¹å¾å’Œæ ‡ç­¾
    X = df.drop(columns=['Fertilizer Name', 'id'])

    y = df['Fertilizer Name'].values
    # âœ… æ·»åŠ è¿™ä¸€æ®µæ¥å¯¹ y è¿›è¡Œç¼–ç 
    # åŠ è½½ LabelEncoder
    le = joblib.load(os.path.join(current_dir, 'label_encoder.pkl'))
    y = le.fit_transform(y)
    print("âœ… ç›®æ ‡å˜é‡å·²ç¼–ç ä¸ºæ•°å€¼ç±»å‹:", dict(enumerate(le.classes_)))

    # ğŸ“Œ å‡è®¾ä½ å·²ç»ä¿å­˜äº† preprocessorï¼š

    preprocessor = joblib.load(os.path.join(current_dir, 'scaler.pkl'))  # ç¤ºä¾‹è·¯å¾„ï¼Œè¯·æ›¿æ¢ä¸ºä½ å®é™…ä¿å­˜çš„ ColumnTransformer
    # åº”ç”¨å˜æ¢ï¼ˆä¸è¿›è¡Œ fitï¼‰
    X_processed = preprocessor.transform(X)

    # åŠ è½½æ¨¡å‹jsonæ–‡ä»¶
    model = XGBClassifier()
    model.load_model("xgboost_model.json")

    print("\nğŸ“‹ å¤šç»“æœæ¨¡å‹è¯„ä¼°ä¸­...")
    y_proba = model.predict_proba(X_processed)
    # è·å– top-3 çš„é¢„æµ‹ç±»åˆ«ç´¢å¼•
    top_3_indices = np.argsort(y_proba, axis=1)[:, -3:]
    y_val_flat = y.ravel()
    # åˆ¤æ–­çœŸå®æ ‡ç­¾æ˜¯å¦åœ¨ top-3 é¢„æµ‹ä¸­
    top_3_correct = np.sum([y_val_flat[i] in top_3_indices[i] for i in range(len(y_val_flat))])
    # è®¡ç®— Top-3 å‡†ç¡®ç‡
    top_3_accuracy = top_3_correct / len(y_val_flat)
    print(f"\nâœ… éªŒè¯é›† Top-3 å‡†ç¡®ç‡: {top_3_accuracy:.4f}")

if __name__ == "__main__":
    main()
    # val()
