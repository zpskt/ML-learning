# 训练数据不均衡
训练数据不均衡，即训练数据中样本数量不均衡，比如训练数据中正样本数量远大于负样本数量。
## 数据分析
首先对训练数据分析
```python
def target_column_analysis():
    # 查看肥料种类及其数量
    print(df_train['Fertilizer Name'].value_counts())

    # 可视化目标变量分布
    sns.countplot(y='Fertilizer Name', data=df_train, order=df_train['Fertilizer Name'].value_counts().index)
    plt.title('Distribution of Fertilizer Names')
    plt.tight_layout()
    plt.show()

```
输出结果为
Fertilizer Name
14-35-14    114436
10-26-26    113887
17-17-17    112453
28-28       111158
20-20       110889
DAP          94860
Urea         92317
Name: count, dtype: int64
可以看到 DAP、Urea的类少于其他几类，在初次训练后，召回率和准确率也显示这两类比较低
## 解决思路
步骤
内容
1️⃣ 使用 SMOTE 或 class_weight 处理类别不平衡
2️⃣ 更换评估指标为 Recall/F1 并观察变化
3️⃣ 使用 StratifiedKFold 交叉验证
4️⃣ 分析 SHAP 特征重要性，加强关键特征建模
5️⃣ 绘制混淆矩阵确认误分类情况
### 1。 数据增强/采样策略
训练数据不均衡，可以通过数据增强或者采样策略来解决。
```python
from imblearn.over_sampling import SMOTE

X = df_train.drop('Fertilizer Name', axis=1)
y = df_train['Fertilizer Name']

smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)
```
b. 下采样（Undersampling）多数类（慎用）
适用于极端样本过多的情况，但可能会丢失信息。

c. 类别不平衡设置权重
这里以XGBoost为例
```python
from sklearn.utils import compute_sample_weight

# 计算每个样本的权重（根据 y_train）
sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)

# 转换为 numpy 数组以确保兼容性
sample_weights = np.array(sample_weights, dtype=np.float32)
```
通过混淆矩阵发现，预测结果出现类别偏好的现象，

### 2. 调整模型评价指标与阈值
a. 使用 F1 或 Recall 作为验证指标
b. 调整分类阈值（适用于概率输出模型）
查看 predict_proba() 输出，手动调整决策边界。
### 3. 特征工程强化少数类区分度
a. 构造新特征
可尝试构造与 DAP、Urea 相关的组合特征或统计特征。
b. SHAP 分析特征重要性
利用 SHAP 值分析哪些特征对 DAP 和 Urea 预测贡献最大，并重点优化这些特征。
### 4. 采用更合适的模型
a. 使用 Ensemble 方法 + Bagging
b. 使用 Cost-sensitive Learning
自定义损失函数，对少数类错误预测加重惩罚。
### 5. 交叉验证策略优化
使用 StratifiedKFold 来确保每一折中各类比例保持一致：
### 6. 可视化辅助诊断
绘制混淆矩阵来具体查看 DAP 和 Urea 是否被误判为哪一类：
```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_true, y_pred)
ConfusionMatrixDisplay(cm).plot()
plt.show()
```